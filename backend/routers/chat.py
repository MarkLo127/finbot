"""
èŠå¤© API è·¯ç”±
è™•ç†è¨˜å¸³æŒ‡ä»¤èˆ‡å°è©±
"""

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from typing import Optional, Dict, Any
from datetime import date
from sqlalchemy.orm import Session

from models.database import get_db
from models.transaction import Transaction
from models.category import Category
from models.conversation import Conversation
from services.nlp_parser import NLPParser
from services.ai_analyzer import AIAnalyzer


router = APIRouter()


class ChatMessage(BaseModel):
    """èŠå¤©è¨Šæ¯"""
    message: str
    source: str = "text"  # "text" æˆ– "voice"


class ChatResponse(BaseModel):
    """èŠå¤©å›è¦†"""
    message: str
    type: str  # "confirmation", "query_result", "analysis", "error"
    data: Optional[Dict[str, Any]] = None


@router.post("/message", response_model=ChatResponse)
async def process_message(chat: ChatMessage, db: Session = Depends(get_db)):
    """
    è™•ç†èŠå¤©è¨Šæ¯
    
    è‡ªå‹•åˆ¤æ–·æ˜¯è¨˜å¸³æŒ‡ä»¤é‚„æ˜¯æŸ¥è©¢/åˆ†æè«‹æ±‚
    """
    text = chat.message.strip()
    
    if not text:
        return ChatResponse(
            message="è«‹è¼¸å…¥è¨Šæ¯",
            type="error"
        )
    
    # åˆ¤æ–·æ„åœ–
    intent = _detect_intent(text)
    
    if intent == "record":
        # è¨˜å¸³æŒ‡ä»¤
        return await _handle_record(text, chat.source, db)
    elif intent == "query":
        # æŸ¥è©¢æŒ‡ä»¤
        return await _handle_query(text, db)
    elif intent == "analysis":
        # åˆ†æ/å°è©±
        return await _handle_analysis(text, db)
    else:
        # é è¨­å˜—è©¦è¨˜å¸³
        return await _handle_record(text, chat.source, db)


def _detect_intent(text: str) -> str:
    """åµæ¸¬ä½¿ç”¨è€…æ„åœ–"""
    # æŸ¥è©¢é—œéµå­—
    query_keywords = ["èŠ±äº†å¤šå°‘", "å¤šå°‘éŒ¢", "æŸ¥è©¢", "çµ±è¨ˆ", "å ±å‘Š", "å ±è¡¨", "è¶¨å‹¢", "åˆ†æåœ–"]
    for kw in query_keywords:
        if kw in text:
            return "query"
    
    # åˆ†æ/å°è©±é—œéµå­—
    analysis_keywords = ["æ˜¯ä¸æ˜¯", "æ‡‰è©²", "å»ºè­°", "å¹«æˆ‘", "ç‚ºä»€éº¼", "æ€éº¼", "å¦‚ä½•"]
    for kw in analysis_keywords:
        if kw in text:
            return "analysis"
    
    # è¨˜å¸³é—œéµå­—ï¼ˆæˆ–åŒ…å«æ•¸å­—ï¼‰
    import re
    if re.search(r'\d+', text):
        return "record"
    
    return "analysis"


async def _handle_record(text: str, source: str, db: Session) -> ChatResponse:
    """è™•ç†è¨˜å¸³æŒ‡ä»¤"""
    # è§£æè¼¸å…¥
    parsed = NLPParser.parse(text)
    
    if not parsed["amount"]:
        return ChatResponse(
            message="æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è­˜åˆ¥é‡‘é¡ã€‚è«‹ç”¨é¡ä¼¼ã€Œåˆé¤ 120 å…ƒã€çš„æ ¼å¼ã€‚",
            type="error"
        )
    
    # æŸ¥æ‰¾é¡åˆ¥
    category = db.query(Category).filter(Category.name == parsed["category"]).first()
    if not category:
        # ä½¿ç”¨é è¨­é¡åˆ¥
        category = db.query(Category).filter(Category.name == "å…¶ä»–").first()
        if not category:
            category = db.query(Category).filter(Category.type == parsed["type"]).first()
    
    if not category:
        return ChatResponse(
            message="ç³»çµ±éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°é¡åˆ¥",
            type="error"
        )
    
    # å»ºç«‹äº¤æ˜“è¨˜éŒ„
    transaction = Transaction(
        amount=parsed["amount"],
        type=parsed["type"],
        category_id=category.id,
        date=parsed["date"],
        description=parsed["description"],
        source=source
    )
    
    db.add(transaction)
    db.commit()
    db.refresh(transaction)
    
    # è¨ˆç®—æœ¬æœˆè©²é¡åˆ¥æ”¯å‡º
    from datetime import date as date_type
    today = date_type.today()
    month_start = today.replace(day=1)
    
    monthly_total = db.query(Transaction).filter(
        Transaction.category_id == category.id,
        Transaction.date >= month_start,
        Transaction.type == "expense"
    ).with_entities(
        db.query(Transaction).column_descriptions[0]['entity'].amount
    ).all()
    
    monthly_sum = sum([t[0] for t in monthly_total]) if monthly_total else parsed["amount"]
    
    # ç”Ÿæˆå›è¦†
    type_text = "æ”¶å…¥" if parsed["type"] == "income" else "æ”¯å‡º"
    date_text = parsed["date"].strftime("%m/%d") if parsed["date"] != date_type.today() else "ä»Šå¤©"
    
    message = f"âœ… å·²è¨˜éŒ„{type_text}ï¼\n\n"
    message += f"ğŸ“ {category.icon} {category.name}\n"
    message += f"ğŸ’° ${parsed['amount']:,.0f}\n"
    message += f"ğŸ“… {date_text}\n"
    
    if parsed["type"] == "expense":
        message += f"\nğŸ“Š æœ¬æœˆ{category.name}ç´¯è¨ˆï¼š${monthly_sum:,.0f}"
    
    return ChatResponse(
        message=message,
        type="confirmation",
        data=transaction.to_dict()
    )


async def _handle_query(text: str, db: Session) -> ChatResponse:
    """è™•ç†æŸ¥è©¢æŒ‡ä»¤"""
    # è§£ææŸ¥è©¢
    query = NLPParser.parse_query(text)
    
    # æŸ¥è©¢äº¤æ˜“
    q = db.query(Transaction).filter(
        Transaction.date >= query["start_date"],
        Transaction.date <= query["end_date"]
    )
    
    if query["category"]:
        category = db.query(Category).filter(Category.name == query["category"]).first()
        if category:
            q = q.filter(Transaction.category_id == category.id)
    
    transactions = q.all()
    
    # è¨ˆç®—çµ±è¨ˆ
    total = sum(t.amount for t in transactions if t.type == "expense")
    
    # ç”Ÿæˆæ‘˜è¦
    if query["category"]:
        message = f"ğŸ“Š {query['category']}æ”¯å‡ºæŸ¥è©¢\n\n"
        message += f"ğŸ“… æœŸé–“ï¼š{query['start_date']} ~ {query['end_date']}\n"
        message += f"ğŸ’¸ ç¸½é‡‘é¡ï¼š${total:,.0f}\n"
        message += f"ğŸ“ å…± {len(transactions)} ç­†äº¤æ˜“"
    else:
        # ä½¿ç”¨æ™ºæ…§æ‘˜è¦
        trans_dicts = [t.to_dict() for t in transactions]
        message = await AIAnalyzer.generate_smart_summary(trans_dicts, query["period"])
    
    return ChatResponse(
        message=message,
        type="query_result",
        data={
            "total": total,
            "count": len(transactions),
            "period": query["period"],
            "chart_type": query["chart_type"],
            "transactions": [t.to_dict() for t in transactions[:20]]  # æœ€å¤šè¿”å› 20 ç­†
        }
    )


async def _handle_analysis(text: str, db: Session) -> ChatResponse:
    """è™•ç† AI åˆ†æè«‹æ±‚"""
    # å–å¾—è¿‘æœŸäº¤æ˜“
    from datetime import timedelta
    today = date.today()
    month_start = today.replace(day=1)
    
    transactions = db.query(Transaction).filter(
        Transaction.date >= month_start
    ).all()
    
    trans_dicts = [t.to_dict() for t in transactions]
    
    # AI åˆ†æ
    response = await AIAnalyzer.analyze_spending(trans_dicts, text)
    
    return ChatResponse(
        message=response,
        type="analysis"
    )


@router.get("/categories")
async def get_categories(db: Session = Depends(get_db)):
    """å–å¾—æ‰€æœ‰é¡åˆ¥"""
    categories = db.query(Category).all()
    return [c.to_dict() for c in categories]
